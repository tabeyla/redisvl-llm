{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redis Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ad187e8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Replace values below with your own if using Redis Cloud instance\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\") # ex: \"redis-18374.c253.us-central1-1.gce.cloud.redislabs.com\"\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")      # ex: 18374\n",
    "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")  # ex: \"1TNxTEdYRDgIDKM2gDfasupCADXXXX\"\n",
    "\n",
    "# If SSL is enabled on the endpoint, use rediss:// as the URL prefix\n",
    "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pfwqHOcqaM_",
    "outputId": "e235bedc-1421-4de7-e7dc-0b09472a35a3"
   },
   "outputs": [],
   "source": [
    "from redis import Redis\n",
    "\n",
    "client = Redis.from_url(REDIS_URL)\n",
    "client.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "Jx80MJF_sgYE",
    "outputId": "709960c6-3cd3-490d-c2c8-86854cad63c7"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# pdf to load\n",
    "path = 'nke-10k-2023.pdf'\n",
    "assert os.path.exists(path), f\"File not found: {path}\"\n",
    "\n",
    "# load and split\n",
    "loader = PyPDFLoader(path)\n",
    "pages = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=0)\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "print(\"Done preprocessing. Created\", len(chunks), \"chunks of the original pdf\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxrE9euAso-r"
   },
   "outputs": [],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mezNLOMCtvDw"
   },
   "source": [
    "# Set Groq as LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Your free Groq API key\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "CHAT_MODEL = \"llama3-70b-8192\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import json\n",
    "\n",
    "def create_dense_props(chunk):\n",
    "    \"\"\"Create dense representation of raw text chunk.\"\"\"\n",
    "\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    You are a helpful PDF extractor tool. You will be presented with segments from\n",
    "    raw PDF documents composed of 10k SEC filings information about public companies.\n",
    "\n",
    "    Decompose and summarize the raw content into clear and simple propositions,\n",
    "    ensuring they are interpretable out of context. Consider the following rules:\n",
    "    1. Split compound sentences into simpler dense phrases that retain existing\n",
    "    meaning.\n",
    "    2. Simplify technical jargon or wording if possible while retaining existing\n",
    "    meaning.\n",
    "    2. For any named entity that is accompanied by additional descriptive information,\n",
    "    separate this information into its own distinct proposition.\n",
    "    3. Decontextualize the proposition by adding necessary modifier to nouns or\n",
    "    entire sentences and replacing pronouns (e.g., \"it\", \"he\", \"she\", \"they\", \"this\", \"that\")\n",
    "    with the full name of the entities they refer to.\n",
    "    4. Present the results as a list of strings, formatted in JSON, under the key \"propositions\".\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=CHAT_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Decompose this raw content using the rules above:\\n{chunk.page_content}\"}\n",
    "    ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    res = response.choices[0].message.content\n",
    "    print(res)\n",
    "    try:\n",
    "        return json.loads(res)[\"propositions\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse propositions\", str(e), flush=True)\n",
    "        # Retry\n",
    "        return create_dense_props(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create text propositions using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from disk to save time or regenerate as needed.\n",
    "try:\n",
    "    with open(\"propositions.json\", \"r\") as f:\n",
    "        propositions = json.load(f)\n",
    "except:\n",
    "    # create props\n",
    "    propositions = [create_dense_props(chunk) for chunk in tqdm.tqdm(chunks)]\n",
    "    propositions = [\" \".join(prop) for prop in propositions]\n",
    " \n",
    "    print(propositions)\n",
    "    \n",
    "    # Save to disk for faster reload..\n",
    "    with open(\"propositions.json\", \"w\") as f:\n",
    "        json.dump(propositions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
